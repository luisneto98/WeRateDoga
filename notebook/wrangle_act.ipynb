{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coleta de Dados WeRateDoga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import tweepy\n",
    "import json\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from operator import itemgetter\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = ''\n",
    "consumer_secret = ''\n",
    "access_token = ''\n",
    "access_secret = ''\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get twitter-archive-enhanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets =  pd.read_csv(\"../Data/twitter-archive-enhanced.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get image_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \" https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv\"\n",
    "r = requests.get(url)\n",
    "with open(\"../Data/image_predictions.tsv\", \"wb\") as code:\n",
    "     code.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_images_predictions = pd.read_csv(\"../Data/image_predictions.tsv\",sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using tweepy for get tweet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_twitter = []\n",
    "for code in df_images_predictions.tweet_id:\n",
    "    try:\n",
    "        status_data = api.get_status(code,tweet_mode='extended')\n",
    "        data_twitter.append(status_data._json)\n",
    "        print(str(code)+\" - encontrado\")\n",
    "    except:\n",
    "        print(str(code)+\" - não encontrado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save downloaded jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../Data/tweet_json.txt\", \"w\") as file:\n",
    "    json.dump(data_twitter,file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load downloaded jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../Data/tweet_json.txt\") as tweet_json:  \n",
    "    data_tweets_json = json.load(tweet_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating dictionary downloaded data with tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_data = []\n",
    "key = 0\n",
    "for data in data_tweets_json:\n",
    "    tweets_data.append({}) \n",
    "    tweets_data[key]['id'] = data['id']\n",
    "    tweets_data[key]['favorite_count'] = data['favorite_count']\n",
    "    tweets_data[key]['retweet_count'] = data['retweet_count']\n",
    "    key = key+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting dictionary to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_data = pd.DataFrame(tweets_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking for trouble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_images_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets.name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_images_predictions.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_tweets.expanded_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_tweets.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quality\n",
    "#### `df_tweets` dataframe\n",
    "- Na coluna name, a falta de informação está sendo preechida com outros valores além de None(\"the\", \"a\")\n",
    "- As colunas retweeted_status_id,retweeted_status_user_id,in_reply_to_status_id e in_reply_to_user_id estão com o tipo float64 causando a perda de informação do valor do id\n",
    "- A coluna source está trazendo toda a informação de uma div\n",
    "- Os valores nulos da coluna expanded_urls estão sendo representados por nan\n",
    "- Na coluna expanded_urls o mesmo url está sendo repetido várias vezes em um mesmo registro\n",
    "- Existem tweets em que o texto começa com RT idicando um retweet\n",
    "- A coluna timestamp não está representando um valor timestamp\n",
    "\n",
    "#### `df_tweets_data` dataframe\n",
    "- Registro faltantes(1457 de 2356)\n",
    "#### Tidiness\n",
    "- As colunas retweeted_status_id,retweeted_status_user_id e retweeted_status_timestamp do df_tweets não são úteis já que não  queremos retweets.\n",
    "- Os dados do dataframe df_tweets_data fazem parte do df_tweets\n",
    "- As colunas doggo, floofer, pupper e puppo respresentam a mesma informação que é o estagio do cão.\n",
    "- O data frame `df_images_predictions` deve ser uma coluna no df_tweets indicando a raça do  cão caso seja possível"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `df_tweets`: Na coluna nome, a falta de informação está sendo preechida com outros valores além de None(\"the\", \"a\",\"an\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "Todos os nomes que foram pegos de forma errada não começam com letra maiúscula, então basta retirar estes e substituir por None."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_clean = df_tweets.copy()\n",
    "for key,row in df_tweets_clean.iterrows():\n",
    "    if(row['name'][0].isupper() == False):\n",
    "        df_tweets_clean['name'][key] = 'None'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_clean.name.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `df_tweets`: As colunas retweeted_status_id,retweeted_status_user_id,in_reply_to_status_id e in_reply_to_user_id estão com o tipo float64 causando a perda de informação do valor do id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "alterar o tipo das colunas usando a função .astype() do pandas tomando cuidado com os valores nulo, substituindo estes por -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_clean.retweeted_status_id = df_tweets_clean.retweeted_status_id.fillna(-1).astype(np.int64,copy=False)\n",
    "df_tweets_clean.retweeted_status_user_id = df_tweets_clean.retweeted_status_user_id.fillna(-1).astype(np.int64,copy=False)\n",
    "df_tweets_clean.in_reply_to_status_id = df_tweets_clean.in_reply_to_status_id.fillna(-1).astype(np.int64,copy=False)\n",
    "df_tweets_clean.in_reply_to_user_id = df_tweets_clean.in_reply_to_user_id.fillna(-1).astype(np.int64,copy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_clean.in_reply_to_status_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_clean.in_reply_to_user_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_clean.retweeted_status_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_clean.retweeted_status_user_id.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `df_tweets`: A coluna source está trazendo toda a informação de uma div"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "percorrer todas as linhas e usar o BeautifulSoup para pegar a informação dentro da div"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = []\n",
    "for source in df_tweets_clean.source:\n",
    "    bs = BeautifulSoup(source,'lxml')\n",
    "    sources.append((bs.find('a').contents[0]))\n",
    "sources\n",
    "df_tweets_clean.source = sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `df_tweets`: Os valores nulos da coluna expanded_urls estão sendo representados por nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "usar a função fillna para alterar os valores NaN para \"None\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_clean.expanded_urls = df_tweets_clean.expanded_urls.fillna('None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `df_tweets`: Na coluna expanded_urls o mesmo url está sendo repetido várias vezes em um mesmo registro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "pecorrer os registros, separar os urls do expanded_urls, retirar os repetidos e atualiizar o registro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_list = []\n",
    "for urls in df_tweets_clean.expanded_urls:\n",
    "    urls_list.append((',').join(list(set(urls.split(',')))))\n",
    "df_tweets_clean.expanded_urls = urls_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for urls in df_tweets_clean.expanded_urls:\n",
    "    print(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `df_tweets`: Existem tweets em que o texto começa com RT idicando um retweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "retirar os dados relativos a RT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,row in df_tweets_clean.iterrows():\n",
    "    if(row.text.find('RT') == 0):\n",
    "        df_tweets_clean = df_tweets_clean.drop(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,row in df_tweets_clean.iterrows():\n",
    "    if(row.text.find('RT') == 0):\n",
    "        print(row.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `df_tweets`: A coluna timestamp não está representando um valor timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "transformar os valores da coluna para timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_clean.timestamp = df_tweets_clean.timestamp.astype('datetime64[ns]').astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_clean.timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `df_tweets_data`:Registro faltantes(1457 de 2356)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "adicionar as linhas faltantes com informações nulas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_data_clean = df_tweets_data.copy()\n",
    "for tweet_id in df_tweets_clean.tweet_id:\n",
    "    if(len(df_tweets_data_clean.loc[df_tweets_data_clean.id == tweet_id]) == 0):\n",
    "        df_tweets_data_clean = df_tweets_data_clean.append({'id':tweet_id,'favorite_count':None,'retweet_count':None},ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_tweets_data_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As colunas retweeted_status_id,retweeted_status_user_id e retweeted_status_timestamp do df_tweets não são úteis já que não  queremos retweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "Retirar as colunas que não são úteis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste = df_tweets_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste.drop(['retweeted_status_id'], axis=1, inplace=True,errors='ignore')\n",
    "df_teste.drop(['retweeted_status_user_id'], axis=1, inplace=True,errors='ignore')\n",
    "df_teste.drop(['retweeted_status_timestamp'], axis=1, inplace=True,errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_clean = df_teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Os dados do dataframe df_tweets_data fazem parte do df_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "Adicionar em df_tweets dos dados de df_tweets_data para cada id relacionado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_data_clean.id = df_tweets_data_clean.id.astype(np.int64)\n",
    "df_tweets_data_clean = df_tweets_data_clean.rename(columns={'id':'tweet_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste = df_tweets_data_clean.copy()\n",
    "df_teste2 = df_tweets_clean.copy()\n",
    "df_master = pd.merge(df_teste2,df_teste,on='tweet_id',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As colunas doggo, floofer, pupper e puppo respresentam a mesma informação que é o estagio do cão."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "Criar uma coluna que sempre vai possuir o valor de uma das colunas, se alguma estiver preenchida. Para isso, \n",
    "pecorrer o df e criar uma coluna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_dog = []\n",
    "for key,row in df_master.iterrows():\n",
    "    stages = {\n",
    "        0:None,\n",
    "        1:'doggo',\n",
    "        2:'floofer',\n",
    "        3:'pupper',\n",
    "        4:'puppo',\n",
    "        5:'multiple'\n",
    "    }\n",
    "    select = 0\n",
    "    if(row.doggo == 'doggo'):\n",
    "        select = 1\n",
    "    if(row.floofer == 'floofer'):\n",
    "        if(select == 0):\n",
    "            select = 2\n",
    "        else:\n",
    "            select = 5\n",
    "    if(row.pupper == 'pupper'):\n",
    "        if(select == 0):\n",
    "            select = 3\n",
    "        else:\n",
    "            select = 5\n",
    "    if(row.puppo == 'puppo'):\n",
    "        if(select == 0):\n",
    "            select = 4\n",
    "        else:\n",
    "            select = 5\n",
    "    stage_dog.append(stages[select])\n",
    "df_master['stage_dog'] = stage_dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master.drop(['floofer','doggo','pupper','puppo'], axis=1, inplace=True,errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master.stage_dog.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### O data frame `df_images_predictions` deve ser uma coluna no df_tweets indicando a raça do  cão caso seja possível"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "Verificar qual predição mais correta e criar uma coluna com estas no dataframe df_images_predctions, clonar e deletar o resto das informações de previsão. Fazer o merge com o master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breed = []\n",
    "df_images_predictions_clean = df_images_predictions.copy()\n",
    "for key,row in df_images_predictions_clean.iterrows():\n",
    "    reliability = 0\n",
    "    dog = None\n",
    "    if(reliability < row.p1_conf and row.p1_dog):\n",
    "        dog = row.p1;\n",
    "        reliability = row.p1_conf\n",
    "    elif(reliability < row.p2_conf and row.p2_dog):\n",
    "        dog = row.p2;\n",
    "        reliability = row.p2_conf\n",
    "    elif(reliability < row.p3_conf and row.p3_dog):\n",
    "        dog = row.p3;\n",
    "        reliability = row.p3_conf\n",
    "    breed.append(dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_images_predictions_clean['breed'] = breed;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_images_predictions_clean.drop(['p1','p2','p3','p1_conf','p2_conf','p3_conf','p1_dog','p2_dog','p3_dog','jpg_url','img_num'], axis=1, inplace=True,errors='ignore')\n",
    "df_master = pd.merge(df_master,df_images_predictions_clean,on='tweet_id',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master.to_csv('../Results/twitter_archive_master.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master_clean = df_master.copy()\n",
    "grade = []\n",
    "for key,row in df_master_clean.iterrows():\n",
    "    if(row.rating_numerator != None and row.rating_denominator != None and row.rating_denominator != 0):\n",
    "        grade.append(row.rating_numerator/row.rating_denominator)\n",
    "    else:\n",
    "        grade.append(None)\n",
    "df_master_clean['grade'] = grade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Media de favorite para cada estagio de cão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "favorite_stage = {'floofer':[],'doggo':[],'pupper':[],'puppo':[],'multiple':[]}\n",
    "for key,row in df_master_clean.iterrows():\n",
    "    if(row.stage_dog != None and row.favorite_count > 0):\n",
    "        favorite_stage[row.stage_dog].append(row.favorite_count)\n",
    "print('floofer: '+str(sum(favorite_stage['floofer'])/len(favorite_stage['floofer'])))\n",
    "print('doggo: '+str(sum(favorite_stage['doggo'])/len(favorite_stage['doggo'])))\n",
    "print('pupper: '+str(sum(favorite_stage['pupper'])/len(favorite_stage['pupper'])))\n",
    "print('puppo: '+str(sum(favorite_stage['puppo'])/len(favorite_stage['puppo'])))\n",
    "print('multiple: '+str(sum(favorite_stage['multiple'])/len(favorite_stage['multiple'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insight:\n",
    "Os cachorros classificados como doggo e puppo são os que conseguem mais favorite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quais as raças de cachorro (top 5) que possuem maior quantidade de favorite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "favorite_breed = {}\n",
    "for key,row in df_master_clean.iterrows():\n",
    "    if(row.breed != None and row.favorite_count > 0):\n",
    "        if(not(row.breed in favorite_breed)):\n",
    "            favorite_breed[row.breed] = []\n",
    "        favorite_breed[row.breed].append(row.favorite_count)\n",
    "print(favorite_breed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for breed in favorite_breed:\n",
    "    favorite_breed[breed] = sum(favorite_breed[breed])/len(favorite_breed[breed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(favorite_breed.items(),key=itemgetter(1),reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A partir dos resultados poodemos ver que as raças que renderam mais favorite foram aquelas  mais exoticas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantidade de favorite para uma  determinada nota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot('grade', 'favorite_count', data=df_master_clean, aspect=2, order=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot('grade', 'favorite_count', data=df_master_clean.loc[df_master_clean.grade <2], aspect=2, order=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retirando as notas muito altas podemos visualizar de forma clara que os tweets que possuem maiores notas tendem a ter mais favorite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
